{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "455e048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0672441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=(5, 5), padding=(2, 2))\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=(5, 5))\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.linear1 = nn.Linear(400, 120, bias=True)\n",
    "        self.linear2 = nn.Linear(120, 84, bias=True)\n",
    "        self.linear3 = nn.Linear(84, 10, bias=True)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        batch_sz = input.shape[0]\n",
    "        x = torch.tanh(self.conv1(input))\n",
    "        x = self.pool1(x)\n",
    "        x = torch.tanh(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(batch_sz, 400)\n",
    "        x = torch.tanh(self.linear1(x))\n",
    "        x = torch.tanh(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc9e21a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 100, bias=False)\n",
    "        self.fc2 = nn.Linear(100, 10, bias=False)\n",
    "    \n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        B = input.shape[0]\n",
    "        \n",
    "        x = input.view(B, 28 * 28).contiguous()\n",
    "        \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d478d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5()\n",
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f7b017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b75fbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a823c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "loader = DataLoader(train_dataset, 50, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "518cbc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ac54b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \t| Step: 0/1200  \t| Loss: 2.3127\n",
      "Epoch: 0 \t| Step: 100/1200  \t| Loss: 2.1899\n",
      "Epoch: 0 \t| Step: 200/1200  \t| Loss: 1.8592\n",
      "Epoch: 0 \t| Step: 300/1200  \t| Loss: 1.6789\n",
      "Epoch: 0 \t| Step: 400/1200  \t| Loss: 1.2358\n",
      "Epoch: 0 \t| Step: 500/1200  \t| Loss: 0.9588\n",
      "Epoch: 0 \t| Step: 600/1200  \t| Loss: 0.9619\n",
      "Epoch: 0 \t| Step: 700/1200  \t| Loss: 0.8801\n",
      "Epoch: 0 \t| Step: 800/1200  \t| Loss: 0.7443\n",
      "Epoch: 0 \t| Step: 900/1200  \t| Loss: 0.6024\n",
      "Epoch: 0 \t| Step: 1000/1200  \t| Loss: 0.4789\n",
      "Epoch: 0 \t| Step: 1100/1200  \t| Loss: 0.5093\n",
      "Epoch: 1 \t| Step: 0/1200  \t| Loss: 0.5705\n",
      "Epoch: 1 \t| Step: 100/1200  \t| Loss: 0.6605\n",
      "Epoch: 1 \t| Step: 200/1200  \t| Loss: 0.5157\n",
      "Epoch: 1 \t| Step: 300/1200  \t| Loss: 0.4178\n",
      "Epoch: 1 \t| Step: 400/1200  \t| Loss: 0.4805\n",
      "Epoch: 1 \t| Step: 500/1200  \t| Loss: 0.4332\n",
      "Epoch: 1 \t| Step: 600/1200  \t| Loss: 0.3471\n",
      "Epoch: 1 \t| Step: 700/1200  \t| Loss: 0.4285\n",
      "Epoch: 1 \t| Step: 800/1200  \t| Loss: 0.4762\n",
      "Epoch: 1 \t| Step: 900/1200  \t| Loss: 0.4460\n",
      "Epoch: 1 \t| Step: 1000/1200  \t| Loss: 0.4115\n",
      "Epoch: 1 \t| Step: 1100/1200  \t| Loss: 0.3643\n",
      "Epoch: 2 \t| Step: 0/1200  \t| Loss: 0.4427\n",
      "Epoch: 2 \t| Step: 100/1200  \t| Loss: 0.5426\n",
      "Epoch: 2 \t| Step: 200/1200  \t| Loss: 0.3187\n",
      "Epoch: 2 \t| Step: 300/1200  \t| Loss: 0.3669\n",
      "Epoch: 2 \t| Step: 400/1200  \t| Loss: 0.3737\n",
      "Epoch: 2 \t| Step: 500/1200  \t| Loss: 0.3788\n",
      "Epoch: 2 \t| Step: 600/1200  \t| Loss: 0.2067\n",
      "Epoch: 2 \t| Step: 700/1200  \t| Loss: 0.3909\n",
      "Epoch: 2 \t| Step: 800/1200  \t| Loss: 0.4647\n",
      "Epoch: 2 \t| Step: 900/1200  \t| Loss: 0.1558\n",
      "Epoch: 2 \t| Step: 1000/1200  \t| Loss: 0.5780\n",
      "Epoch: 2 \t| Step: 1100/1200  \t| Loss: 0.6203\n",
      "Epoch: 3 \t| Step: 0/1200  \t| Loss: 0.3745\n",
      "Epoch: 3 \t| Step: 100/1200  \t| Loss: 0.3987\n",
      "Epoch: 3 \t| Step: 200/1200  \t| Loss: 0.3744\n",
      "Epoch: 3 \t| Step: 300/1200  \t| Loss: 0.2318\n",
      "Epoch: 3 \t| Step: 400/1200  \t| Loss: 0.3037\n",
      "Epoch: 3 \t| Step: 500/1200  \t| Loss: 0.4039\n",
      "Epoch: 3 \t| Step: 600/1200  \t| Loss: 0.3282\n",
      "Epoch: 3 \t| Step: 700/1200  \t| Loss: 0.2289\n",
      "Epoch: 3 \t| Step: 800/1200  \t| Loss: 0.1878\n",
      "Epoch: 3 \t| Step: 900/1200  \t| Loss: 0.2759\n",
      "Epoch: 3 \t| Step: 1000/1200  \t| Loss: 0.2122\n",
      "Epoch: 3 \t| Step: 1100/1200  \t| Loss: 0.6866\n",
      "Epoch: 4 \t| Step: 0/1200  \t| Loss: 0.3640\n",
      "Epoch: 4 \t| Step: 100/1200  \t| Loss: 0.1785\n",
      "Epoch: 4 \t| Step: 200/1200  \t| Loss: 0.3333\n",
      "Epoch: 4 \t| Step: 300/1200  \t| Loss: 0.2723\n",
      "Epoch: 4 \t| Step: 400/1200  \t| Loss: 0.1781\n",
      "Epoch: 4 \t| Step: 500/1200  \t| Loss: 0.1982\n",
      "Epoch: 4 \t| Step: 600/1200  \t| Loss: 0.4067\n",
      "Epoch: 4 \t| Step: 700/1200  \t| Loss: 0.2512\n",
      "Epoch: 4 \t| Step: 800/1200  \t| Loss: 0.2186\n",
      "Epoch: 4 \t| Step: 900/1200  \t| Loss: 0.2635\n",
      "Epoch: 4 \t| Step: 1000/1200  \t| Loss: 0.2289\n",
      "Epoch: 4 \t| Step: 1100/1200  \t| Loss: 0.1629\n",
      "Epoch: 5 \t| Step: 0/1200  \t| Loss: 0.5586\n",
      "Epoch: 5 \t| Step: 100/1200  \t| Loss: 0.2449\n",
      "Epoch: 5 \t| Step: 200/1200  \t| Loss: 0.1583\n",
      "Epoch: 5 \t| Step: 300/1200  \t| Loss: 0.3511\n",
      "Epoch: 5 \t| Step: 400/1200  \t| Loss: 0.3515\n",
      "Epoch: 5 \t| Step: 500/1200  \t| Loss: 0.2194\n",
      "Epoch: 5 \t| Step: 600/1200  \t| Loss: 0.2641\n",
      "Epoch: 5 \t| Step: 700/1200  \t| Loss: 0.3990\n",
      "Epoch: 5 \t| Step: 800/1200  \t| Loss: 0.2781\n",
      "Epoch: 5 \t| Step: 900/1200  \t| Loss: 0.1341\n",
      "Epoch: 5 \t| Step: 1000/1200  \t| Loss: 0.6532\n",
      "Epoch: 5 \t| Step: 1100/1200  \t| Loss: 0.5135\n",
      "Epoch: 6 \t| Step: 0/1200  \t| Loss: 0.4267\n",
      "Epoch: 6 \t| Step: 100/1200  \t| Loss: 0.1726\n",
      "Epoch: 6 \t| Step: 200/1200  \t| Loss: 0.2454\n",
      "Epoch: 6 \t| Step: 300/1200  \t| Loss: 0.3620\n",
      "Epoch: 6 \t| Step: 400/1200  \t| Loss: 0.1348\n",
      "Epoch: 6 \t| Step: 500/1200  \t| Loss: 0.3253\n",
      "Epoch: 6 \t| Step: 600/1200  \t| Loss: 0.2736\n",
      "Epoch: 6 \t| Step: 700/1200  \t| Loss: 0.3250\n",
      "Epoch: 6 \t| Step: 800/1200  \t| Loss: 0.3615\n",
      "Epoch: 6 \t| Step: 900/1200  \t| Loss: 0.3391\n",
      "Epoch: 6 \t| Step: 1000/1200  \t| Loss: 0.2253\n",
      "Epoch: 6 \t| Step: 1100/1200  \t| Loss: 0.2425\n",
      "Epoch: 7 \t| Step: 0/1200  \t| Loss: 0.2863\n",
      "Epoch: 7 \t| Step: 100/1200  \t| Loss: 0.4498\n",
      "Epoch: 7 \t| Step: 200/1200  \t| Loss: 0.3175\n",
      "Epoch: 7 \t| Step: 300/1200  \t| Loss: 0.2778\n",
      "Epoch: 7 \t| Step: 400/1200  \t| Loss: 0.3725\n",
      "Epoch: 7 \t| Step: 500/1200  \t| Loss: 0.3247\n",
      "Epoch: 7 \t| Step: 600/1200  \t| Loss: 0.1673\n",
      "Epoch: 7 \t| Step: 700/1200  \t| Loss: 0.1788\n",
      "Epoch: 7 \t| Step: 800/1200  \t| Loss: 0.4657\n",
      "Epoch: 7 \t| Step: 900/1200  \t| Loss: 0.3894\n",
      "Epoch: 7 \t| Step: 1000/1200  \t| Loss: 0.2259\n",
      "Epoch: 7 \t| Step: 1100/1200  \t| Loss: 0.2864\n",
      "Epoch: 8 \t| Step: 0/1200  \t| Loss: 0.1938\n",
      "Epoch: 8 \t| Step: 100/1200  \t| Loss: 0.1361\n",
      "Epoch: 8 \t| Step: 200/1200  \t| Loss: 0.2480\n",
      "Epoch: 8 \t| Step: 300/1200  \t| Loss: 0.3742\n",
      "Epoch: 8 \t| Step: 400/1200  \t| Loss: 0.2058\n",
      "Epoch: 8 \t| Step: 500/1200  \t| Loss: 0.2591\n",
      "Epoch: 8 \t| Step: 600/1200  \t| Loss: 0.4769\n",
      "Epoch: 8 \t| Step: 700/1200  \t| Loss: 0.2846\n",
      "Epoch: 8 \t| Step: 800/1200  \t| Loss: 0.3678\n",
      "Epoch: 8 \t| Step: 900/1200  \t| Loss: 0.2421\n",
      "Epoch: 8 \t| Step: 1000/1200  \t| Loss: 0.1495\n",
      "Epoch: 8 \t| Step: 1100/1200  \t| Loss: 0.1518\n",
      "Epoch: 9 \t| Step: 0/1200  \t| Loss: 0.2107\n",
      "Epoch: 9 \t| Step: 100/1200  \t| Loss: 0.1507\n",
      "Epoch: 9 \t| Step: 200/1200  \t| Loss: 0.1676\n",
      "Epoch: 9 \t| Step: 300/1200  \t| Loss: 0.1552\n",
      "Epoch: 9 \t| Step: 400/1200  \t| Loss: 0.3955\n",
      "Epoch: 9 \t| Step: 500/1200  \t| Loss: 0.1873\n",
      "Epoch: 9 \t| Step: 600/1200  \t| Loss: 0.2158\n",
      "Epoch: 9 \t| Step: 700/1200  \t| Loss: 0.2714\n",
      "Epoch: 9 \t| Step: 800/1200  \t| Loss: 0.3788\n",
      "Epoch: 9 \t| Step: 900/1200  \t| Loss: 0.3359\n",
      "Epoch: 9 \t| Step: 1000/1200  \t| Loss: 0.1557\n",
      "Epoch: 9 \t| Step: 1100/1200  \t| Loss: 0.1770\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (inp, outp) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(inp)\n",
    "        loss = criterion(logits, outp)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch: {epoch} \\t| Step: {i}/{len(loader)}  \\t| Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "010d17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, 1000, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5bcd0c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of batch (0/10): 0.9270\n",
      "Accuracy of batch (1/10): 0.9420\n",
      "Accuracy of batch (2/10): 0.9330\n",
      "Accuracy of batch (3/10): 0.9240\n",
      "Accuracy of batch (4/10): 0.9340\n",
      "Accuracy of batch (5/10): 0.9410\n",
      "Accuracy of batch (6/10): 0.9330\n",
      "Accuracy of batch (7/10): 0.9290\n",
      "Accuracy of batch (8/10): 0.9500\n",
      "Accuracy of batch (9/10): 0.9310\n",
      "Accuracy: 0.9344000220298767\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pos = 0\n",
    "length = 0\n",
    "\n",
    "for i, (inp, outp) in enumerate(test_loader):\n",
    "    logits = model(inp)\n",
    "    true_pos = torch.softmax(logits, dim=-1).argmax(-1) == outp\n",
    "    print(f'Accuracy of batch ({i}/{int(len(test_dataset)/test_loader.batch_size)}): {true_pos.sum()/test_loader.batch_size:.4f}')\n",
    "    pos += true_pos.sum()\n",
    "    length += test_loader.batch_size\n",
    "\n",
    "print(f'Accuracy: {pos/length}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
